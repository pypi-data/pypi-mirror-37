# -*- coding: utf-8 -*-

"""
pywebcopy.generators
~~~~~~~~~~~~~~~~~~~~

Data & patterns generators powering pywebcopy.
"""


import re
import sys
import io

from . import LOGGER, SESSION
from .config import config
from .utils import relate
from . import utils
from .urls import Url, filename_present, pathname2url
from .elements import Asset
from .elements import LinkTag
from .elements import ScriptTag
from .elements import ImgTag
from .elements import Asset
from .exceptions import InvalidUrlError, RequiredAttributesMissing
from .core import get, new_file


PY3 = (sys.version_info[0] == 3)
CSS_URLS = re.compile(b'''url\\(['|"]?(.*?)["|']?\\)''')


class AssetsGenerator(object):
    """Provides operations on beautifulSoup objects."""

    def __init__(self, parsed_content, url_obj):
        """Creates and saves linked file on webpage.
        """
        self.soup = parsed_content
        self.url_obj = url_obj
        self.css_urls_re = CSS_URLS
        self.replace_url = True


    def extract_css_urls(url_obj, contents=None):
        """
        Extracts url() links in css and saves and
        replaces them in file
        all the linked file url() will be saved and file path
        would be replaced accordingly

        """
        file_path = url_obj.file_path()

        if not contents:
            try:
                # read the file
                LOGGER.debug('Reading Existing file at %s' % file_path)
                contents = open(file_path, 'rb').read()
                LOGGER.debug('Finding CSS urls in file %s' % file_path)

            except Exception as e:
                LOGGER.critical(e)
                LOGGER.critical('Failed to open file %s for CSS urls search' % file_path)
                return

        # the regex matches all those with double mix-match quotes and normal ones
        # also have to strip down the mix match quotes
        _urls = CSS_URLS.findall(contents)

        # if links are not found
        if len(_urls) == 0:
            LOGGER.info('No CSS linked files are found in file %s' % file_path)
            return contents

        # links are found, now extract and save them
        LOGGER.info('%d CSS linked files are found in file %s' % (len(_urls), file_path))

        for _url in _urls:
            # Urls may have double unequal quotes which is due to re pattern limitation
            # urls are in bytes format which creates error when doing url operations
            # thus have to be suppressed
            try:
                _str_url = _url.encode('utf8')
            except Exception as e:
                LOGGER.debug(e)
                LOGGER.debug("Conversion to unicode failed for the url %r" % _url)
                continue

            # url can be base64 encoded content which is not required to be stored
            if _str_url[:4] == 'data':
                continue

            try:
                # a path is generated by the cssAsset object and tried to store the file
                # but file could be corrupted to open or write
                _obj = Asset(_str_url)
                _obj.base_url = self.url_obj.url
                _obj.base_path = config['project_folder']
                _obj.save_file()

            except Exception as e:
                LOGGER.error(e)
                LOGGER.error("File failed to be Saved! %s" % _str_url)
                continue

            # generate a relative path for this downloaded file
            _rel_url = pathname2url(utils.relate(
                _obj.file_path(), file_path
            ))
            LOGGER.debug('Replacing linked file path %s by %s' % (_str_url, _rel_url))

            # save the location of the downloaded file on the original file
            if PY3:
                # reconvert to bytes
                _rel_url = bytes(_rel_url, "utf8")
                contents = contents.replace(_url, _rel_url)
            else:
                _rel_url = bytes(_rel_url)
                contents = contents.replace(_url, _rel_url)

        if not contents:
            # rewrite the original file to contain the newly downloaded file links
            with open(file_path, 'wb') as orig_file:
                orig_file.write(contents)

        else:
            return contents

    def css_elements(self):
        """Returns a generator containing every css type file used on page.

        Filename check is not required because the css request can be of many
        type like google-web-fonts which never have a filename, hence additionally
        the LinkTag object have ability to generate random names.
        """

        for elem in self.soup.find_all('link', href=True):
            if not elem.get('href'):
                continue
            yield LinkTag(elem.get('href'))

    def js_elements(self):
        """Returns a generator containing every js type file used on page.

        This additionally checks that linked file has an file name.
        """
        for elem in self.soup.find_all('script', src=True):
            if not filename_present(elem.get('src')):
                continue
            yield ScriptTag(elem.get('src'))

    def img_elements(self):
        """Returns a generator containing every img type file used on page.

        This also checks that linked file has an file name.
        Filename check helps prevents downloader from attempting download of
        any base64 encoded data or any malformed image link.
        """
        for elem in self.soup.find_all('img', src=True):
            if not filename_present(elem.get('src')):
                continue
            yield ImgTag(elem.get('src'))

    def save_css_files(self):
        """Saves every css or favicon files found on the page and replace their location on self.soup object."""

        # It can be blocked by global config key
        if config['load_css']:

            # Finds every <link> html element and tries to save them otherwise skips
            # to the next element without generating any error
            for elem in self.soup.find_all('link', href=True):
                LOGGER.debug('Generating Asset obj for found url %s' % elem['href'])
                if elem.get('crossorigin'):
                    del elem['crossorigin']
                if elem.get('integrity'):
                    del elem['integrity']
                if elem.get('srcset'):
                    del elem['srcset']
                try:
                    # Generate a css specific object which contains every path and url
                    # new in version 3.0.0
                    url_obj = LinkTag(elem.get('href', ''))
                    url_obj.base_url = self.url_obj.url

                    req = get(url_obj.url)

                    if not req or not req.ok:
                        raise InvalidUrlError("Url returned an unknown response %s" % self.url_obj.url)

                    content = self.extract_css_urls(contents=req.content, url_obj=url_obj)

                    new_file(location=url_obj.file_path, content=content)
                    if self.replace_url:
                        elem['href'] = pathname2url(utils.relate(url_obj.file_path,
                                                                 self.url_obj.file_path))

                except Exception as e:
                    LOGGER.error(e)
                    LOGGER.error("Failed to generate LinkTag obj for %s" % elem.get('href', ''))
                    continue

                LOGGER.info('Sending %s file for CSS urls search!' % url_obj.file_path)

        else:
            LOGGER.info("CSS Saving is disabled in config!")
            return

    def save_js_files(self):
        """Saves the js files and replaces their location on the self.soup object."""

        # Download of the javascript can be blocked by the confiuration key
        if config['LOAD_JAVASCRIPT']:
            for elem in self.soup.find_all('script', src=True):
                LOGGER.debug('Generating Asset obj for found url %s' % elem['src'])
                if elem.get('crossorigin'):
                    del elem['crossorigin']
                if elem.get('integrity'):
                    del elem['integrity']
                if elem.get('srcset'):
                    del elem['srcset']
                try:
                    # Generate a js specific object which contains every path and url
                    # new in version 3.0.0
                    url_obj = ScriptTag(elem.get('src', ''))
                    url_obj.base_url = self.url_obj.url
                    url_obj.save_file()

                    if self.replace_url:
                        elem['src'] = pathname2url(utils.relate(url_obj.file_path,
                                                                self.url_obj.file_path))

                except Exception as e:
                    LOGGER.error(e.message)
                    LOGGER.error("Failed to generate ScriptTag obj for %s" % elem.get('src', ''))
                    continue
        else:
            LOGGER.info("Javascript Saving is disabled in config!")
            return

    def save_img_files(self):
        """Saves the imgs files and replaces their location on the self.soup object."""

        # if image download is allowed
        if config['LOAD_IMAGES']:
            for elem in self.soup.find_all('img', src=True):
                LOGGER.debug('Generating Asset obj for found url %s' % elem['src'])
                for i in ['crossorigin', 'integrity', 'srcset', 'data-srcset', 'data-src']:
                    if elem.get(i):
                        del elem[i]

                try:
                    # Generate a imgs specific object which contains every path and url
                    # new in version 3.0.0
                    url_obj = ImgTag(elem.get('src', ''))
                    url_obj.base_url = self.url_obj.url
                    url_obj.save_file()

                    if self.replace_url:
                        elem['src'] = pathname2url(utils.relate(url_obj.file_path,
                                                                self.url_obj.file_path))
                except Exception as e:
                    LOGGER.error(e.message)
                    LOGGER.error("Failed to generate ImgTag obj for %s" % elem.get('src', ''))
                    continue
        else:
            LOGGER.info("Images Saving is disabled in config!")
            return

    def generate_style_map(self):
        """ Saves css, js and img to disk and replaces their location on
        page soup.

        Generates file soup with links to files and pages converted from
        absolute to relative for preventing file not found error while
        browsing offline

        :return: None

        """

        LOGGER.info('Running asset save on file %s' % self.url_obj.file_path)

        # just calls the objects functions sequentially
        self.save_css_files()
        self.save_js_files()
        self.save_img_files()

        LOGGER.info("Style map generation completed!")
        return


