{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyQCore Tutorial  \n",
    "  \n",
    "This tutorial is for PyQCore Library.  \n",
    "In this tutorial, we use Japanese Vowels Data Set hosted by UCI.  \n",
    "    https://archive.ics.uci.edu/ml/datasets/Japanese+Vowels  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pyqcore.client import SimpleQCoreClient\n",
    "from pyqcore.examples.jpvow import load_jpvow\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first load data and split them for training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_jpvow()\n",
    "    # Train: 80% / Test: 20%\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    data.data, data.target, test_size=0.2, random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create an API instance and get access token. Make sure that you need get license code from [QuantumCore Website](https://www.qcore.co.jp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===WAVECORE(Sample)===\n",
      "{'access_token': ''}\n"
     ]
    }
   ],
   "source": [
    "print(\"===WAVECORE(Sample)===\")\n",
    "# create API instance\n",
    "client = SimpleQCoreClient()\n",
    "# get token (login)\n",
    "access_token = client.login(\n",
    "        username=\"#USER#\", password=\"#PASS#\", endpoint=\"http://#ENDPOINT#\"\n",
    ")\n",
    "print(access_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for training and classification.  \n",
    "Our engine adopts Rest-API interface, and SimpleQCoreClient makes it easy to convert data to json format and send it to the engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 29, 12)\n",
      "{'res': 'ok', 'train_time': 0.05660191774368286}\n",
      "{'accuracy': 0.9921875, 'f1': 0.9921496212121212, 'res': 'ok'}\n",
      "acc= 0.9921875\n",
      "f1= 0.9921496212121212\n",
      "elapsed_time:15.333560943603516[sec]\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "start = time.time()\n",
    "print(X_train.shape)\n",
    "res = client.classifier_train(X=X_train, Y=y_train, access_token=access_token)\n",
    "print(res)\n",
    "\n",
    "# test\n",
    "res = client.classifier_test(X=X_test, Y=y_test, access_token=access_token)\n",
    "print(res)\n",
    "    \n",
    "# classify\n",
    "res = client.classifier_predict(X=X_test, access_token=access_token)\n",
    "print(\"acc=\", accuracy_score(y_test.tolist(), res[\"Y\"]))\n",
    "print(\"f1=\", f1_score(y_test.tolist(), res[\"Y\"], average=\"weighted\"))\n",
    "elapsed_time = time.time() - start\n",
    "print(\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that our model is currently running on AWS t2.micro instace. In other words, this model runs with tiny CPU, memory and no GPU ([check out the spec here](https://aws.amazon.com/ec2/instance-types/)).  \n",
    "Now let's compare to other model. In this demo, we use Logistic Regression and simple Neural Network(MLP) on Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===LogisticRegression(Using Sklearn)===\n",
      "elapsed_time:0.1800389289855957[sec]\n",
      "acc= 0.9765625\n",
      "f1= 0.9761245153216563\n",
      "===MLP(Using Sklearn)===\n",
      "elapsed_time:0.5161328315734863[sec]\n",
      "acc= 0.9609375\n",
      "f1= 0.9602246632305703\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(len(X_train), -1).astype(np.float64)\n",
    "X_test = X_test.reshape(len(X_test), -1).astype(np.float64)\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)\n",
    "\n",
    "print(\"===LogisticRegression(Using Sklearn)===\")\n",
    "start = time.time()\n",
    "lr_cls = LogisticRegression(C=9.0)\n",
    "lr_cls.fit(X_train, y_train)\n",
    "elapsed_time = time.time() - start\n",
    "print(\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "res = lr_cls.predict(X=X_test)\n",
    "print(\"acc=\", accuracy_score(y_test.tolist(), res))\n",
    "print(\"f1=\", f1_score(y_test.tolist(), res, average=\"weighted\"))\n",
    "\n",
    "print(\"===MLP(Using Sklearn)===\")\n",
    "start = time.time()\n",
    "mlp_cls = MLPClassifier(hidden_layer_sizes=(100, 100, 100, 10))\n",
    "mlp_cls.fit(X_train, y_train)\n",
    "elapsed_time = time.time() - start\n",
    "print(\"elapsed_time:{0}\".format(elapsed_time) + \"[sec]\")\n",
    "res = mlp_cls.predict(X=X_test)\n",
    "print(\"acc=\", accuracy_score(y_test.tolist(), res))\n",
    "print(\"f1=\", f1_score(y_test.tolist(), res, average=\"weighted\"))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
